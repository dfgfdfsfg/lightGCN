{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 定义超参数类"
      ],
      "metadata": {
        "id": "a0twLhenbu4D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nY46S9x5TJUe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import multiprocessing\n",
        "import sys\n",
        "import os\n",
        "from os.path import join\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "\"\"\"定义超参数\"\"\"\n",
        "class params:\n",
        "  def __init__(self,bpr_batch_size=2048,latent_dim_rec=64,lightGCN_n_layers=3,\n",
        "               dropout=0,keep_prob=0.6,A_n_fold=100,seed=2024,\n",
        "               test_u_batch_size=100,epochs=1000,dataset=\"gowalla\",\n",
        "               load=1,path=\"./checkpoints\",topks='[20]',\n",
        "               multicore=0,lr=0.001,decay=1e-4,pretrain=0,\n",
        "               A_split=False,bigdata=False,comment=\"lgn\"):\n",
        "    self.config={}\n",
        "    self.config['bpr_batch_size'] = bpr_batch_size\n",
        "    self.config['latent_dim_rec'] = latent_dim_rec\n",
        "    self.config['lightGCN_n_layers']= lightGCN_n_layers\n",
        "    self.config['dropout'] = dropout\n",
        "    self.config['keep_prob']  = keep_prob\n",
        "    self.config['A_n_fold'] = A_n_fold\n",
        "    self.config['test_u_batch_size'] = test_u_batch_size\n",
        "    self.config['multicore'] = multicore\n",
        "    self.config['lr'] = lr\n",
        "    self.config['decay'] = decay\n",
        "    self.config['pretrain'] = pretrain\n",
        "    self.config['A_split'] = A_split\n",
        "    self.config['bigdata'] = bigdata\n",
        "    GPU = torch.cuda.is_available()\n",
        "    self.device = torch.device('cuda' if GPU else \"cpu\")\n",
        "    self.CORES = multiprocessing.cpu_count() // 2\n",
        "    self.seed = seed\n",
        "    self.ROOT_PATH = os.getcwd()\n",
        "    self.CODE_PATH = join(self.ROOT_PATH, 'code')\n",
        "    self.DATA_PATH = join(self.ROOT_PATH, 'data')\n",
        "    self.BOARD_PATH = join(self.CODE_PATH, 'runs')\n",
        "    self.FILE_PATH = join(self.CODE_PATH, 'checkpoints')\n",
        "    sys.path.append(join(self.CODE_PATH, 'sources'))\n",
        "    if not os.path.exists(self.FILE_PATH):\n",
        "        os.makedirs(self.FILE_PATH, exist_ok=True)\n",
        "    self.dataset = dataset\n",
        "    self.TRAIN_epochs = epochs\n",
        "    self.LOAD = load\n",
        "    self.PATH = path\n",
        "    self.topks = eval(topks)\n",
        "    self.comment = comment\n",
        "    self.logo = r\"\"\"\n",
        "        ███╗   ███╗  ██████╗ ██╗\n",
        "        ████╗ ████║ ██╔════╝ ██║\n",
        "        ██╔████╔██║ ██║      ██║\n",
        "        ██║╚██╔╝██║ ██║      ██║\n",
        "        ██║ ╚═╝ ██║ ╚██████╗ ███████╗\n",
        "        ╚═╝     ╚═╝  ╚═════╝ ╚══════╝\n",
        "      \"\"\"\n",
        "  def cprint(self,words : str):\n",
        "    print(f\"\\033[0;30;43m{words}\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "检验代码能跑嘛"
      ],
      "metadata": {
        "id": "_rJo7aRkaK6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "world = params()\n",
        "print(world.logo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNm3nbBBYtKT",
        "outputId": "2af2c5dc-417f-467c-8aab-0ee2d6547d4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        ███╗   ███╗  ██████╗ ██╗\n",
            "        ████╗ ████║ ██╔════╝ ██║\n",
            "        ██╔████╔██║ ██║      ██║\n",
            "        ██║╚██╔╝██║ ██║      ██║\n",
            "        ██║ ╚═╝ ██║ ╚██████╗ ███████╗\n",
            "        ╚═╝     ╚═╝  ╚═════╝ ╚══════╝\n",
            "      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 定义数据加载器类"
      ],
      "metadata": {
        "id": "HDRbNaj0ijyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import join\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.sparse import csr_matrix\n",
        "import scipy.sparse as sp\n",
        "from time import time\n",
        "world = params()\n",
        "class Loader():\n",
        "    \"\"\"\n",
        "    Dataset type for pytorch \\n\n",
        "    Incldue graph information\n",
        "    gowalla dataset\n",
        "    \"\"\"\n",
        "    def __init__(self,config = world.config,path=\"../data/gowalla\"):\n",
        "        # train or test\n",
        "        world.cprint(f'loading [{path}]')\n",
        "        self.split = config['A_split']\n",
        "        self.folds = config['A_n_fold']\n",
        "        self.mode_dict = {'train': 0, \"test\": 1}\n",
        "        self.mode = self.mode_dict['train']\n",
        "        self.n_user = 0\n",
        "        self.m_item = 0\n",
        "        train_file = path + '/content/train.txt'\n",
        "        test_file = path + '/content/test.txt'\n",
        "        self.path = path\n",
        "        trainUniqueUsers, trainItem, trainUser = [], [], []\n",
        "        testUniqueUsers, testItem, testUser = [], [], []\n",
        "        self.traindataSize = 0\n",
        "        self.testDataSize = 0\n",
        "\n",
        "        with open(train_file) as f:\n",
        "            for l in f.readlines():\n",
        "                if len(l) > 0:\n",
        "                    l = l.strip('\\n').split(' ')\n",
        "                    items = [int(i) for i in l[1:]]\n",
        "                    uid = int(l[0])\n",
        "                    trainUniqueUsers.append(uid)\n",
        "                    trainUser.extend([uid] * len(items))\n",
        "                    trainItem.extend(items)\n",
        "                    self.m_item = max(self.m_item, max(items))\n",
        "                    self.n_user = max(self.n_user, uid)\n",
        "                    self.traindataSize += len(items)\n",
        "        self.trainUniqueUsers = np.array(trainUniqueUsers)\n",
        "        self.trainUser = np.array(trainUser)\n",
        "        self.trainItem = np.array(trainItem)\n",
        "\n",
        "        with open(test_file) as f:\n",
        "            for l in f.readlines():\n",
        "                if len(l) > 0:\n",
        "                    l = l.strip('\\n').split(' ')\n",
        "                    items = [int(i) for i in l[1:]]\n",
        "                    uid = int(l[0])\n",
        "                    testUniqueUsers.append(uid)\n",
        "                    testUser.extend([uid] * len(items))\n",
        "                    testItem.extend(items)\n",
        "                    self.m_item = max(self.m_item, max(items))\n",
        "                    self.n_user = max(self.n_user, uid)\n",
        "                    self.testDataSize += len(items)\n",
        "        self.m_item += 1\n",
        "        self.n_user += 1\n",
        "        self.testUniqueUsers = np.array(testUniqueUsers)\n",
        "        self.testUser = np.array(testUser)\n",
        "        self.testItem = np.array(testItem)\n",
        "\n",
        "        self.Graph = None\n",
        "        print(f\"{self.trainDataSize} interactions for training\")\n",
        "        print(f\"{self.testDataSize} interactions for testing\")\n",
        "        print(f\"{world.dataset} Sparsity : {(self.trainDataSize + self.testDataSize) / self.n_users / self.m_items}\")\n",
        "\n",
        "        # (users,items), bipartite graph\n",
        "        self.UserItemNet = csr_matrix((np.ones(len(self.trainUser)), (self.trainUser, self.trainItem)),\n",
        "                                      shape=(self.n_user, self.m_item))\n",
        "        self.users_D = np.array(self.UserItemNet.sum(axis=1)).squeeze()\n",
        "        self.users_D[self.users_D == 0.] = 1\n",
        "        self.items_D = np.array(self.UserItemNet.sum(axis=0)).squeeze()\n",
        "        self.items_D[self.items_D == 0.] = 1.\n",
        "        # pre-calculate\n",
        "        self._allPos = self.getUserPosItems(list(range(self.n_user)))\n",
        "        self.__testDict = self.__build_test()\n",
        "        print(f\"{world.dataset} is ready to go\")\n",
        "\n",
        "    @property\n",
        "    def n_users(self):\n",
        "        return self.n_user\n",
        "\n",
        "    @property\n",
        "    def m_items(self):\n",
        "        return self.m_item\n",
        "\n",
        "    @property\n",
        "    def trainDataSize(self):\n",
        "        return self.traindataSize\n",
        "\n",
        "    @property\n",
        "    def testDict(self):\n",
        "        return self.__testDict\n",
        "\n",
        "    @property\n",
        "    def allPos(self):\n",
        "        return self._allPos\n",
        "\n",
        "    def _split_A_hat(self,A):\n",
        "        A_fold = []\n",
        "        fold_len = (self.n_users + self.m_items) // self.folds\n",
        "        for i_fold in range(self.folds):\n",
        "            start = i_fold*fold_len\n",
        "            if i_fold == self.folds - 1:\n",
        "                end = self.n_users + self.m_items\n",
        "            else:\n",
        "                end = (i_fold + 1) * fold_len\n",
        "            A_fold.append(self._convert_sp_mat_to_sp_tensor(A[start:end]).coalesce().to(world.device))\n",
        "        return A_fold\n",
        "\n",
        "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
        "        coo = X.tocoo().astype(np.float32)\n",
        "        row = torch.Tensor(coo.row).long()\n",
        "        col = torch.Tensor(coo.col).long()\n",
        "        index = torch.stack([row, col])\n",
        "        data = torch.FloatTensor(coo.data)\n",
        "        return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))\n",
        "\n",
        "    def getSparseGraph(self):\n",
        "        print(\"loading adjacency matrix\")\n",
        "        if self.Graph is None:\n",
        "            try:\n",
        "                pre_adj_mat = sp.load_npz(self.path + '/s_pre_adj_mat.npz')\n",
        "                print(\"successfully loaded...\")\n",
        "                norm_adj = pre_adj_mat\n",
        "            except :\n",
        "                print(\"generating adjacency matrix\")\n",
        "                s = time()\n",
        "                adj_mat = sp.dok_matrix((self.n_users + self.m_items, self.n_users + self.m_items), dtype=np.float32)\n",
        "                adj_mat = adj_mat.tolil()\n",
        "                R = self.UserItemNet.tolil()\n",
        "                adj_mat[:self.n_users, self.n_users:] = R\n",
        "                adj_mat[self.n_users:, :self.n_users] = R.T\n",
        "                adj_mat = adj_mat.todok()\n",
        "                # adj_mat = adj_mat + sp.eye(adj_mat.shape[0])\n",
        "\n",
        "                rowsum = np.array(adj_mat.sum(axis=1))\n",
        "                d_inv = np.power(rowsum, -0.5).flatten()\n",
        "                d_inv[np.isinf(d_inv)] = 0.\n",
        "                d_mat = sp.diags(d_inv)\n",
        "\n",
        "                norm_adj = d_mat.dot(adj_mat)\n",
        "                norm_adj = norm_adj.dot(d_mat)\n",
        "                norm_adj = norm_adj.tocsr()\n",
        "                end = time()\n",
        "                print(f\"costing {end-s}s, saved norm_mat...\")\n",
        "                sp.save_npz(self.path + '/s_pre_adj_mat.npz', norm_adj)\n",
        "\n",
        "            if self.split == True:\n",
        "                self.Graph = self._split_A_hat(norm_adj)\n",
        "                print(\"done split matrix\")\n",
        "            else:\n",
        "                self.Graph = self._convert_sp_mat_to_sp_tensor(norm_adj)\n",
        "                self.Graph = self.Graph.coalesce().to(world.device)\n",
        "                print(\"don't split the matrix\")\n",
        "        return self.Graph\n",
        "\n",
        "    def __build_test(self):\n",
        "        \"\"\"\n",
        "        return:\n",
        "            dict: {user: [items]}\n",
        "        \"\"\"\n",
        "        test_data = {}\n",
        "        for i, item in enumerate(self.testItem):\n",
        "            user = self.testUser[i]\n",
        "            if test_data.get(user):\n",
        "                test_data[user].append(item)\n",
        "            else:\n",
        "                test_data[user] = [item]\n",
        "        return test_data\n",
        "\n",
        "    def getUserItemFeedback(self, users, items):\n",
        "        \"\"\"\n",
        "        users:\n",
        "            shape [-1]\n",
        "        items:\n",
        "            shape [-1]\n",
        "        return:\n",
        "            feedback [-1]\n",
        "        \"\"\"\n",
        "        # print(self.UserItemNet[users, items])\n",
        "        return np.array(self.UserItemNet[users, items]).astype('uint8').reshape((-1,))\n",
        "\n",
        "    def getUserPosItems(self, users):\n",
        "        posItems = []\n",
        "        for user in users:\n",
        "            posItems.append(self.UserItemNet[user].nonzero()[1])\n",
        "        return posItems\n"
      ],
      "metadata": {
        "id": "7ieG4FsWii-q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 定义light-gcn模型"
      ],
      "metadata": {
        "id": "sc59ACQ0qqca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "CORES = multiprocessing.cpu_count() // 2\n",
        "\n",
        "class LightGCN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 config:dict,\n",
        "                 dataset:Loader,\n",
        "                 world:params):\n",
        "        super(LightGCN, self).__init__()\n",
        "        self.config = config\n",
        "        self.dataset = dataset\n",
        "        self.world = world\n",
        "        self.__init_weight()\n",
        "\n",
        "    def __init_weight(self):\n",
        "        self.num_users  = self.dataset.n_users\n",
        "        self.num_items  = self.dataset.m_items\n",
        "        self.latent_dim = self.config['latent_dim_rec']\n",
        "        self.n_layers = self.config['lightGCN_n_layers']\n",
        "        self.keep_prob = self.config['keep_prob']\n",
        "        self.A_split = self.config['A_split']\n",
        "        self.embedding_user = torch.nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.latent_dim)\n",
        "        self.embedding_item = torch.nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.latent_dim)\n",
        "        if self.config['pretrain'] == 0:\n",
        "            nn.init.normal_(self.embedding_user.weight, std=0.1)\n",
        "            nn.init.normal_(self.embedding_item.weight, std=0.1)\n",
        "            world.cprint('use NORMAL distribution initilizer')\n",
        "        else:\n",
        "            self.embedding_user.weight.data.copy_(torch.from_numpy(self.config['user_emb']))\n",
        "            self.embedding_item.weight.data.copy_(torch.from_numpy(self.config['item_emb']))\n",
        "            print('use pretarined data')\n",
        "        self.f = nn.Sigmoid()\n",
        "        self.Graph = self.dataset.getSparseGraph()\n",
        "        print(f\"lgn is already to go(dropout:{self.config['dropout']})\")\n",
        "\n",
        "    def __dropout_x(self, x, keep_prob):\n",
        "        size = x.size()\n",
        "        index = x.indices().t()\n",
        "        values = x.values()\n",
        "        random_index = torch.rand(len(values)) + keep_prob\n",
        "        random_index = random_index.int().bool()\n",
        "        index = index[random_index]\n",
        "        values = values[random_index]/keep_prob\n",
        "        g = torch.sparse.FloatTensor(index.t(), values, size)\n",
        "        return g\n",
        "\n",
        "    def __dropout(self, keep_prob):\n",
        "        if self.A_split:\n",
        "            graph = []\n",
        "            for g in self.Graph:\n",
        "                graph.append(self.__dropout_x(g, keep_prob))\n",
        "        else:\n",
        "            graph = self.__dropout_x(self.Graph, keep_prob)\n",
        "        return graph\n",
        "\n",
        "    def computer(self):\n",
        "        \"\"\"\n",
        "        propagate methods for lightGCN\n",
        "        \"\"\"\n",
        "        users_emb = self.embedding_user.weight\n",
        "        items_emb = self.embedding_item.weight\n",
        "        all_emb = torch.cat([users_emb, items_emb])\n",
        "        embs = [all_emb]\n",
        "        if self.config['dropout']:\n",
        "            if self.training:\n",
        "                print(\"droping\")\n",
        "                g_droped = self.__dropout(self.keep_prob)\n",
        "            else:\n",
        "                g_droped = self.Graph\n",
        "        else:\n",
        "            g_droped = self.Graph\n",
        "\n",
        "        for layer in range(self.n_layers):\n",
        "            if self.A_split:\n",
        "                temp_emb = []\n",
        "                for f in range(len(g_droped)):\n",
        "                    temp_emb.append(torch.sparse.mm(g_droped[f], all_emb))\n",
        "                side_emb = torch.cat(temp_emb, dim=0)\n",
        "                all_emb = side_emb\n",
        "            else:\n",
        "                all_emb = torch.sparse.mm(g_droped, all_emb)\n",
        "            embs.append(all_emb)\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "\n",
        "        light_out = torch.mean(embs, dim=1)\n",
        "        users, items = torch.split(light_out, [self.num_users, self.num_items])\n",
        "        return users, items\n",
        "\n",
        "    def getUsersRating(self, users):\n",
        "        all_users, all_items = self.computer()\n",
        "        users_emb = all_users[users.long()]\n",
        "        items_emb = all_items\n",
        "        rating = self.f(torch.matmul(users_emb, items_emb.t()))\n",
        "        return rating\n",
        "\n",
        "    def getEmbedding(self, users, pos_items, neg_items):\n",
        "        all_users, all_items = self.computer()\n",
        "        users_emb = all_users[users]\n",
        "        pos_emb = all_items[pos_items]\n",
        "        neg_emb = all_items[neg_items]\n",
        "        users_emb_ego = self.embedding_user(users)\n",
        "        pos_emb_ego = self.embedding_item(pos_items)\n",
        "        neg_emb_ego = self.embedding_item(neg_items)\n",
        "        return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego\n",
        "\n",
        "    def shuffle(self,*arrays, **kwargs):\n",
        "\n",
        "        require_indices = kwargs.get('indices', False)\n",
        "\n",
        "        if len(set(len(x) for x in arrays)) != 1:\n",
        "            raise ValueError('All inputs to shuffle must have '\n",
        "                             'the same length.')\n",
        "\n",
        "        shuffle_indices = np.arange(len(arrays[0]))\n",
        "        np.random.shuffle(shuffle_indices)\n",
        "\n",
        "        if len(arrays) == 1:\n",
        "            result = arrays[0][shuffle_indices]\n",
        "        else:\n",
        "            result = tuple(x[shuffle_indices] for x in arrays)\n",
        "\n",
        "        if require_indices:\n",
        "            return result, shuffle_indices\n",
        "        else:\n",
        "            return result\n",
        "    def minibatch(self,*tensors, **kwargs):\n",
        "\n",
        "        batch_size = kwargs.get('batch_size', self.world.config['bpr_batch_size'])\n",
        "\n",
        "        if len(tensors) == 1:\n",
        "            tensor = tensors[0]\n",
        "            for i in range(0, len(tensor), batch_size):\n",
        "                yield tensor[i:i + batch_size]\n",
        "        else:\n",
        "            for i in range(0, len(tensors[0]), batch_size):\n",
        "                yield tuple(x[i:i + batch_size] for x in tensors)\n",
        "\n",
        "    def bpr_loss(self, users, pos, neg):\n",
        "        (users_emb, pos_emb, neg_emb,\n",
        "        userEmb0,  posEmb0, negEmb0) = self.getEmbedding(users.long(), pos.long(), neg.long())\n",
        "        reg_loss = (1/2)*(userEmb0.norm(2).pow(2) +\n",
        "                         posEmb0.norm(2).pow(2)  +\n",
        "                         negEmb0.norm(2).pow(2))/float(len(users))\n",
        "        pos_scores = torch.mul(users_emb, pos_emb)\n",
        "        pos_scores = torch.sum(pos_scores, dim=1)\n",
        "        neg_scores = torch.mul(users_emb, neg_emb)\n",
        "        neg_scores = torch.sum(neg_scores, dim=1)\n",
        "\n",
        "        loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
        "\n",
        "        return loss, reg_loss\n",
        "\n",
        "    def UniformSample_original_python(self,dataset):\n",
        "      \"\"\"\n",
        "      the original impliment of BPR Sampling in LightGCN\n",
        "      :return:\n",
        "          np.array\n",
        "      \"\"\"\n",
        "      user_num = dataset.trainDataSize\n",
        "      users = np.random.randint(0, dataset.n_users, user_num)\n",
        "      allPos = dataset.allPos\n",
        "      S = []\n",
        "      sample_time1 = 0.\n",
        "      sample_time2 = 0.\n",
        "      for i, user in enumerate(users):\n",
        "          start = time()\n",
        "          posForUser = allPos[user]\n",
        "          if len(posForUser) == 0:\n",
        "              continue\n",
        "          posindex = np.random.randint(0, len(posForUser))\n",
        "          positem = posForUser[posindex]\n",
        "          while True:\n",
        "              negitem = np.random.randint(0, dataset.m_items)\n",
        "              if negitem in posForUser:\n",
        "                  continue\n",
        "              else:\n",
        "                  break\n",
        "          S.append([user, positem, negitem])\n",
        "      return np.array(S)\n",
        "\n",
        "    def BPR_train_original(self,dataset, recommend_model, loss_class, epoch, neg_k=1, w=None):\n",
        "        Recmodel = recommend_model\n",
        "        Recmodel.train()\n",
        "        bpr: BPRLoss = loss_class\n",
        "        S = self.UniformSample_original_python(dataset)\n",
        "        users = torch.Tensor(S[:, 0]).long()\n",
        "        posItems = torch.Tensor(S[:, 1]).long()\n",
        "        negItems = torch.Tensor(S[:, 2]).long()\n",
        "\n",
        "        users = users.to(self.world.device)\n",
        "        posItems = posItems.to(self.world.device)\n",
        "        negItems = negItems.to(self.world.device)\n",
        "        users, posItems, negItems = self.shuffle(users, posItems, negItems)\n",
        "        total_batch = len(users) // self.world.config['bpr_batch_size'] + 1\n",
        "        aver_loss = 0.\n",
        "        for (batch_i,\n",
        "             (batch_users,\n",
        "              batch_pos,\n",
        "              batch_neg)) in enumerate(self.minibatch(users,\n",
        "                                   posItems,\n",
        "                                   negItems,\n",
        "                                   batch_size=self.world.config['bpr_batch_size'])):\n",
        "            cri = bpr.stageOne(batch_users, batch_pos, batch_neg)\n",
        "            aver_loss += cri\n",
        "        aver_loss = aver_loss / total_batch\n",
        "        return f\"loss{aver_loss:.3f}\"\n",
        "\n",
        "    def getLabel(self,test_data, pred_data):\n",
        "        r = []\n",
        "        for i in range(len(test_data)):\n",
        "            groundTrue = test_data[i]\n",
        "            predictTopK = pred_data[i]\n",
        "            pred = list(map(lambda x: x in groundTrue, predictTopK))\n",
        "            pred = np.array(pred).astype(\"float\")\n",
        "            r.append(pred)\n",
        "        return np.array(r).astype('float')\n",
        "\n",
        "    def RecallPrecision_ATk(self,test_data, r, k):\n",
        "        \"\"\"\n",
        "        test_data should be a list? cause users may have different amount of pos items. shape (test_batch, k)\n",
        "        pred_data : shape (test_batch, k) NOTE: pred_data should be pre-sorted\n",
        "        k : top-k\n",
        "        \"\"\"\n",
        "        right_pred = r[:, :k].sum(1)\n",
        "        precis_n = k\n",
        "        recall_n = np.array([len(test_data[i]) for i in range(len(test_data))])\n",
        "        recall = np.sum(right_pred/recall_n)\n",
        "        precis = np.sum(right_pred)/precis_n\n",
        "        return {'recall': recall, 'precision': precis}\n",
        "\n",
        "    def NDCGatK_r(self,test_data,r,k):\n",
        "        \"\"\"\n",
        "        Normalized Discounted Cumulative Gain\n",
        "        rel_i = 1 or 0, so 2^{rel_i} - 1 = 1 or 0\n",
        "        \"\"\"\n",
        "        assert len(r) == len(test_data)\n",
        "        pred_data = r[:, :k]\n",
        "\n",
        "        test_matrix = np.zeros((len(pred_data), k))\n",
        "        for i, items in enumerate(test_data):\n",
        "            length = k if k <= len(items) else len(items)\n",
        "            test_matrix[i, :length] = 1\n",
        "        test_matrix[0, :length] = 1\n",
        "        max_r = test_matrix\n",
        "        idcg = np.sum(max_r * 1./np.log2(np.arange(2, k + 2)), axis=1)\n",
        "        dcg = pred_data*(1./np.log2(np.arange(2, k + 2)))\n",
        "        dcg = np.sum(dcg, axis=1)\n",
        "        idcg[idcg == 0.] = 1.\n",
        "        ndcg = dcg/idcg\n",
        "        ndcg[np.isnan(ndcg)] = 0.\n",
        "        return np.sum(ndcg)\n",
        "\n",
        "    def test_one_batch(self,X):\n",
        "        sorted_items = X[0].numpy()\n",
        "        #sorted_items = X[0]\n",
        "        groundTrue = X[1]\n",
        "        r = self.getLabel(groundTrue, sorted_items)\n",
        "        pre, recall, ndcg = [], [], []\n",
        "        for k in world.topks:\n",
        "            ret = self.RecallPrecision_ATk(groundTrue, r, k)\n",
        "            pre.append(ret['precision'])\n",
        "            recall.append(ret['recall'])\n",
        "            ndcg.append(self.NDCGatK_r(groundTrue,r,k))\n",
        "        return {'recall':np.array(recall),\n",
        "                'precision':np.array(pre),\n",
        "                'ndcg':np.array(ndcg)}\n",
        "\n",
        "\n",
        "    def Test(self,dataset, Recmodel, epoch):\n",
        "        u_batch_size = self.world.config['test_u_batch_size']\n",
        "        testDict: dict = dataset.testDict\n",
        "        # eval mode with no dropout\n",
        "        Recmodel = Recmodel.eval()\n",
        "        max_K = max(self.world.topks)\n",
        "\n",
        "        results = {'precision': np.zeros(len(world.topks)),\n",
        "                   'recall': np.zeros(len(world.topks)),\n",
        "                   'ndcg': np.zeros(len(world.topks))}\n",
        "        with torch.no_grad():\n",
        "            users = list(testDict.keys())\n",
        "            try:\n",
        "                assert u_batch_size <= len(users) / 10\n",
        "            except AssertionError:\n",
        "                print(f\"test_u_batch_size is too big for this dataset, try a small one {len(users) // 10}\")\n",
        "            users_list = []\n",
        "            rating_list = []\n",
        "            groundTrue_list = []\n",
        "            # auc_record = []\n",
        "            # ratings = []\n",
        "            total_batch = len(users) // u_batch_size + 1\n",
        "            for batch_users in self.minibatch(users, batch_size=u_batch_size):\n",
        "                allPos = dataset.getUserPosItems(batch_users)\n",
        "                groundTrue = [testDict[u] for u in batch_users]\n",
        "                batch_users_gpu = torch.Tensor(batch_users).long()\n",
        "                batch_users_gpu = batch_users_gpu.to(self.world.device)\n",
        "\n",
        "                rating = Recmodel.getUsersRating(batch_users_gpu)\n",
        "                #rating = rating.cpu()\n",
        "                exclude_index = []\n",
        "                exclude_items = []\n",
        "                for range_i, items in enumerate(allPos):\n",
        "                    exclude_index.extend([range_i] * len(items))\n",
        "                    exclude_items.extend(items)\n",
        "                rating[exclude_index, exclude_items] = -(1<<10)\n",
        "                _, rating_K = torch.topk(rating, k=max_K)\n",
        "                rating = rating.cpu().numpy()\n",
        "                # aucs = [\n",
        "                #         utils.AUC(rating[i],\n",
        "                #                   dataset,\n",
        "                #                   test_data) for i, test_data in enumerate(groundTrue)\n",
        "                #     ]\n",
        "                # auc_record.extend(aucs)\n",
        "                del rating\n",
        "                users_list.append(batch_users)\n",
        "                rating_list.append(rating_K.cpu())\n",
        "                groundTrue_list.append(groundTrue)\n",
        "            assert total_batch == len(users_list)\n",
        "            X = zip(rating_list, groundTrue_list)\n",
        "            pre_results = []\n",
        "            for x in X:\n",
        "                pre_results.append(self.test_one_batch(x))\n",
        "            scale = float(u_batch_size/len(users))\n",
        "            for result in pre_results:\n",
        "                results['recall'] += result['recall']\n",
        "                results['precision'] += result['precision']\n",
        "                results['ndcg'] += result['ndcg']\n",
        "            results['recall'] /= float(len(users))\n",
        "            results['precision'] /= float(len(users))\n",
        "            results['ndcg'] /= float(len(users))\n",
        "            # results['auc'] = np.mean(auc_record)\n",
        "            print(results)\n",
        "            return results\n",
        "\n",
        "    def pred(self,dataset,Recmodel):\n",
        "        u_batch_size = self.world.config['test_u_batch_size']\n",
        "        testDict: dict = dataset.testDict\n",
        "        Recmodel = Recmodel.eval()\n",
        "        max_K = max(self.world.topks)\n",
        "        with torch.no_grad():\n",
        "            users = list(testDict.keys())\n",
        "            try:\n",
        "                assert u_batch_size <= len(users) / 10\n",
        "            except AssertionError:\n",
        "                print(f\"test_u_batch_size is too big for this dataset, try a small one {len(users) // 10}\")\n",
        "            users_list = []\n",
        "            rating_list = []\n",
        "            groundTrue_list = []\n",
        "            # auc_record = []\n",
        "            # ratings = []\n",
        "            total_batch = len(users) // u_batch_size + 1\n",
        "            for batch_users in self.minibatch(users, batch_size=u_batch_size):\n",
        "                allPos = dataset.getUserPosItems(batch_users)\n",
        "                batch_users_gpu = torch.Tensor(batch_users).long()\n",
        "                batch_users_gpu = batch_users_gpu.to(self.world.device)\n",
        "\n",
        "                rating = Recmodel.getUsersRating(batch_users_gpu)\n",
        "                #rating = rating.cpu()\n",
        "                exclude_index = []\n",
        "                exclude_items = []\n",
        "                for range_i, items in enumerate(allPos):\n",
        "                    exclude_index.extend([range_i] * len(items))\n",
        "                    exclude_items.extend(items)\n",
        "                rating[exclude_index, exclude_items] = -(1<<10)\n",
        "                _, rating_K = torch.topk(rating, k=max_K)\n",
        "                del rating\n",
        "                rating_list.append(rating_K.cpu())\n",
        "            print(\"输出成功！\")\n",
        "            return rating_list\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        all_users, all_items = self.computer()\n",
        "        users_emb = all_users[users]\n",
        "        items_emb = all_items[items]\n",
        "        inner_pro = torch.mul(users_emb, items_emb)\n",
        "        gamma     = torch.sum(inner_pro, dim=1)\n",
        "        return gamma"
      ],
      "metadata": {
        "id": "A-UH10XEqpwc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 定义Bpr_loss"
      ],
      "metadata": {
        "id": "OcQ6iaaFsoQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "from torch import log\n",
        "from time import time\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import random\n",
        "import os\n",
        "\n",
        "class BPRLoss:\n",
        "    def __init__(self,\n",
        "                 recmodel : LightGCN,\n",
        "                 config : dict):\n",
        "        self.model = recmodel\n",
        "        self.weight_decay = config['decay']\n",
        "        self.lr = config['lr']\n",
        "        self.opt = optim.Adam(recmodel.parameters(), lr=self.lr)\n",
        "\n",
        "    def stageOne(self, users, pos, neg):\n",
        "        loss, reg_loss = self.model.bpr_loss(users, pos, neg)\n",
        "        reg_loss = reg_loss*self.weight_decay\n",
        "        loss = loss + reg_loss\n",
        "\n",
        "        self.opt.zero_grad()\n",
        "        loss.backward()\n",
        "        self.opt.step()\n",
        "\n",
        "        return loss.cpu().item()"
      ],
      "metadata": {
        "id": "sqKDy99fsn4t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 主函数"
      ],
      "metadata": {
        "id": "KN6467p8bs7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Procedure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6t6uWiafOGT",
        "outputId": "0885d8ab-0838-4398-ff2c-ea2e0536bf6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Procedure in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from Procedure) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->Procedure) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->Procedure) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->Procedure) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->Procedure) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->Procedure) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "world = params()\n",
        "#定义随机数种子，保证结果的可复现性\n",
        "np.random.seed(world.seed)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(world.seed)\n",
        "  torch.cuda.manual_seed_all(world.seed)\n",
        "torch.manual_seed(world.seed)\n",
        "print(\">>SEED:\", world.seed)\n",
        "dataset = Loader(path=\"\")\n",
        "print('===========config================')\n",
        "pprint(world.config)\n",
        "print(\"cores for test:\", world.CORES)\n",
        "print(\"comment:\", world.comment)\n",
        "print(\"LOAD:\", world.LOAD)\n",
        "print(\"Weight path:\", world.PATH)\n",
        "print(\"Test Topks:\", world.topks)\n",
        "print(\"using bpr loss\")\n",
        "print('===========end===================')\n",
        "Recmodel = LightGCN(world.config, dataset, world)\n",
        "Recmodel = Recmodel.to(world.device)\n",
        "bpr = BPRLoss(Recmodel, world.config)\n",
        "file = f\"lgn-{world.dataset}-{world.config['lightGCN_n_layers']}-{world.config['latent_dim_rec']}.pth.tar\"\n",
        "weight_path = os.path.join(world.FILE_PATH, file)\n",
        "print(f\"load and save to {weight_path}\")\n",
        "if world.LOAD:\n",
        "    try:\n",
        "        Recmodel.load_state_dict(torch.load(weight_path, map_location=torch.device('cpu')))\n",
        "        world.cprint(f\"loaded model weights from {weight_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"{weight_path} not exists, start from beginning\")\n",
        "Neg_k = 1\n",
        "#Recmodel.Test(dataset, Recmodel, 1, world.config['multicore'])\n",
        "for epoch in range(world.TRAIN_epochs):\n",
        "    if epoch % 10 == 0:\n",
        "        world.cprint(\"[TEST]\")\n",
        "        Recmodel.Test(dataset, Recmodel, epoch)\n",
        "    output_information = Recmodel.BPR_train_original(dataset, Recmodel, bpr, epoch, neg_k=Neg_k)\n",
        "    print(f'EPOCH[{epoch + 1}/{world.TRAIN_epochs}] {output_information}')\n",
        "    torch.save(Recmodel.state_dict(), weight_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n8crSxBedOBS",
        "outputId": "d0c513bd-89a8-4b7e-8a12-e3d344ac7495"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>SEED: 2024\n",
            "\u001b[0;30;43mloading []\u001b[0m\n",
            "810128 interactions for training\n",
            "217242 interactions for testing\n",
            "gowalla Sparsity : 0.0008396216228570436\n",
            "gowalla is ready to go\n",
            "===========config================\n",
            "{'A_n_fold': 100,\n",
            " 'A_split': False,\n",
            " 'bigdata': False,\n",
            " 'bpr_batch_size': 2048,\n",
            " 'decay': 0.0001,\n",
            " 'dropout': 0,\n",
            " 'keep_prob': 0.6,\n",
            " 'latent_dim_rec': 64,\n",
            " 'lightGCN_n_layers': 3,\n",
            " 'lr': 0.001,\n",
            " 'multicore': 0,\n",
            " 'pretrain': 0,\n",
            " 'test_u_batch_size': 100}\n",
            "cores for test: 1\n",
            "comment: lgn\n",
            "LOAD: 1\n",
            "Weight path: ./checkpoints\n",
            "Test Topks: [20]\n",
            "using bpr loss\n",
            "===========end===================\n",
            "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n",
            "loading adjacency matrix\n",
            "generating adjacency matrix\n",
            "costing 116.80713701248169s, saved norm_mat...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9553e781e580>:124: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)\n",
            "  return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "don't split the matrix\n",
            "lgn is already to go(dropout:0)\n",
            "load and save to /content/code/checkpoints/lgn-gowalla-3-64.pth.tar\n",
            "/content/code/checkpoints/lgn-gowalla-3-64.pth.tar not exists, start from beginning\n",
            "\u001b[0;30;43m[TEST]\u001b[0m\n",
            "29858\n",
            "[13.072087]\n",
            "{'precision': array([0.00022774]), 'recall': array([0.00067513]), 'ndcg': array([0.00043781])}\n",
            "EPOCH[1/1000] loss0.548\n",
            "EPOCH[2/1000] loss0.239\n",
            "EPOCH[3/1000] loss0.160\n",
            "EPOCH[4/1000] loss0.129\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-40e7ab4ff067>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[TEST]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mRecmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0moutput_information\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBPR_train_original\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNeg_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'EPOCH[{epoch + 1}/{world.TRAIN_epochs}] {output_information}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-83fa12f0ad84>\u001b[0m in \u001b[0;36mBPR_train_original\u001b[0;34m(self, dataset, recommend_model, loss_class, epoch, neg_k, w)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                    \u001b[0mnegItems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                                    batch_size=self.world.config['bpr_batch_size'])):\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mcri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstageOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0maver_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0maver_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maver_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fc139f935148>\u001b[0m in \u001b[0;36mstageOne\u001b[0;34m(self, users, pos, neg)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 生成最后的输出文件，请将该生成的文件提交到kaggle"
      ],
      "metadata": {
        "id": "d8nvoCcvv7rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import csv\n",
        "world = params()\n",
        "#定义随机数种子，保证结果的可复现性\n",
        "np.random.seed(world.seed)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(world.seed)\n",
        "  torch.cuda.manual_seed_all(world.seed)\n",
        "torch.manual_seed(world.seed)\n",
        "print(\">>SEED:\", world.seed)\n",
        "dataset = Loader(path=\"\")\n",
        "print('===========config================')\n",
        "pprint(world.config)\n",
        "print(\"cores for test:\", world.CORES)\n",
        "print(\"comment:\", world.comment)\n",
        "print(\"LOAD:\", world.LOAD)\n",
        "print(\"Weight path:\", world.PATH)\n",
        "print(\"Test Topks:\", world.topks)\n",
        "print(\"using bpr loss\")\n",
        "print('===========end===================')\n",
        "Recmodel = LightGCN(world.config, dataset, world)\n",
        "Recmodel = Recmodel.to(world.device)\n",
        "file = f\"lgn-{world.dataset}-{world.config['lightGCN_n_layers']}-{world.config['latent_dim_rec']}.pth.tar\"\n",
        "weight_path = os.path.join(world.FILE_PATH, file)\n",
        "print(f\"load and save to {weight_path}\")\n",
        "if world.LOAD:\n",
        "    try:\n",
        "        Recmodel.load_state_dict(torch.load(weight_path, map_location=torch.device('cpu')))\n",
        "        world.cprint(f\"loaded model weights from {weight_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"{weight_path} not exists, start from beginning\")\n",
        "Recmodel.Test(dataset, Recmodel, 1)\n",
        "u_pred = Recmodel.pred(dataset,Recmodel)\n",
        "output_file = 'submission.csv'\n",
        "col_list = ['id']\n",
        "col_list+= [f\"col_{i}\" for i in range(1,21)]\n",
        "cnt = 0\n",
        "with open(output_file, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    tensor_list = []\n",
        "    for u_pred_sub in u_pred:\n",
        "        for i in range(len(u_pred_sub)):\n",
        "            list_ = [cnt]\n",
        "            cnt+=1\n",
        "            list_ += u_pred_sub[i].tolist()\n",
        "            tensor_list.append(list_)\n",
        "    writer.writerow(col_list)\n",
        "    writer.writerows(tensor_list)\n",
        "\n",
        "print(f\"张量已成功写入到 {output_file}\")"
      ],
      "metadata": {
        "id": "SHwpS8n0wGfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f5ab7c-37fb-4f3a-fde8-0b5c380ab1f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>SEED: 2024\n",
            "\u001b[0;30;43mloading []\u001b[0m\n",
            "810128 interactions for training\n",
            "217242 interactions for testing\n",
            "gowalla Sparsity : 0.0008396216228570436\n",
            "gowalla is ready to go\n",
            "===========config================\n",
            "{'A_n_fold': 100,\n",
            " 'A_split': False,\n",
            " 'bigdata': False,\n",
            " 'bpr_batch_size': 2048,\n",
            " 'decay': 0.0001,\n",
            " 'dropout': 0,\n",
            " 'keep_prob': 0.6,\n",
            " 'latent_dim_rec': 64,\n",
            " 'lightGCN_n_layers': 3,\n",
            " 'lr': 0.001,\n",
            " 'multicore': 0,\n",
            " 'pretrain': 0,\n",
            " 'test_u_batch_size': 100}\n",
            "cores for test: 1\n",
            "comment: lgn\n",
            "LOAD: 1\n",
            "Weight path: ./checkpoints\n",
            "Test Topks: [20]\n",
            "using bpr loss\n",
            "===========end===================\n",
            "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n",
            "loading adjacency matrix\n",
            "successfully loaded...\n",
            "don't split the matrix\n",
            "lgn is already to go(dropout:0)\n",
            "load and save to /content/code/checkpoints/lgn-gowalla-3-64.pth.tar\n",
            "\u001b[0;30;43mloaded model weights from /content/code/checkpoints/lgn-gowalla-3-64.pth.tar\u001b[0m\n",
            "29858\n",
            "[2948.0498845]\n",
            "{'precision': array([0.03607408]), 'recall': array([0.11810592]), 'ndcg': array([0.09873568])}\n",
            "输出成功！\n",
            "张量已成功写入到 submission.csv\n"
          ]
        }
      ]
    }
  ]
}